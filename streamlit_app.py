import streamlit as st
import pandas as pd
import io
import requests
from datetime import datetime

st.set_page_config(page_title="å°è‚¡ç±Œç¢¼è§€æ¸¬ç«™ (ç›´æ¥é€£ç·šç‰ˆ)", layout="wide")

def get_data_direct(target_date):
    date_str = target_date.strftime("%Y%m%d")
    # æ”¹ç”¨ CSV ä¸‹è¼‰ç¶²å€ï¼Œé€™èˆ‡ JSON æ¥å£çš„è·¯å¾‘ä¸åŒï¼Œæœ‰æ©Ÿæœƒç¹éé˜»æ“‹
    url = f"https://www.twse.com.tw/zh/trading/fund/BFI82U/download?queryDate={date_str}&type=csv"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    try:
        response = requests.get(url, headers=headers, timeout=20)
        
        # å¦‚æœé‚„æ˜¯è¢«æ“‹ï¼ˆå›å‚³ HTMLï¼‰ï¼Œé€™è¡ŒæœƒæŠ“åˆ°
        if "<html>" in response.text:
            return None, "é€£ç·šè¢«è­‰äº¤æ‰€æ‹’çµ• (IP å°é–)ã€‚"

        # ä½¿ç”¨ io.StringIO å°‡å­—ä¸²è½‰ç‚ºæª”æ¡ˆæ ¼å¼ä¾› pandas è®€å–
        # è­‰äº¤æ‰€ CSV é€šå¸¸å¾ç¬¬ 2 è¡Œé–‹å§‹æ‰æ˜¯è³‡æ–™
        df = pd.read_csv(io.StringIO(response.text), skiprows=1)
        
        # æ¸…ç†è³‡æ–™ï¼šç§»é™¤å…¨ç©ºçš„æ¬„ä½æˆ–åˆè¨ˆåˆ—
        df = df.dropna(subset=['å–®ä½åç¨±'])
        return df, f"{date_str} ä¸‰å¤§æ³•äººè²·è³£è¶…"
        
    except Exception as e:
        return None, f"æŠ“å–å¤±æ•—: {str(e)}"

# --- UI ä»‹é¢ ---
st.title("ğŸ“ˆ å°è‚¡ç±Œç¢¼è§€å¯Ÿç«™ (CSV ç›´æ¥é€£ç·š)")

# æ¸¬è©¦æ™‚è«‹æ‰‹å‹•é¸å– 2026/01/12
query_date = st.date_input("é¸æ“‡æŸ¥è©¢æ—¥æœŸ", value=datetime(2026, 1, 12))

if st.button("åŸ·è¡ŒæŠ“å–", use_container_width=True):
    with st.spinner('å˜—è©¦ç›´æ¥é€£ç·šè­‰äº¤æ‰€ CSV ä¼ºæœå™¨...'):
        df, msg = get_data_direct(query_date)
        
        if df is not None:
            st.success(msg)
            st.dataframe(df, use_container_width=True, hide_index=True)
        else:
            st.error(msg)
            st.info("ç›®å‰çš„é›²ç«¯ IP å¯èƒ½å·²è¢«è­‰äº¤æ‰€æš«æ™‚åˆ—å…¥é»‘åå–®ã€‚")
